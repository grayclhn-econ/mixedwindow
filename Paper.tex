\documentclass[11pt,fleqn]{article}

\usepackage{amsfonts}
\usepackage{amsmath,amsthm,amssymb,graphicx,setspace,url,booktabs,tabularx,enumerate,slantsc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[nolists,nomarkers]{endfloat}
\usepackage[sort,round,comma]{natbib}
\usepackage[margin=1.25in]{geometry}
\usepackage[small]{caption}
\newcolumntype{C}{>{\centering\arraybackslash}X}

\bibliographystyle{abbrvnat}
\newcommand\citepos[2][]{\citeauthor{#2}'s \citeyearpar[#1]{#2}}
\newcommand\poscw{\citeauthor{ClW:06}'s \citeyearpar{ClW:06,ClW:07}}
\newcommand\citen[1]{\citeauthor{#1}, \citeyear{#1}}
\frenchspacing
\input{tex/mcDef}
\input{tex/ap}

\newtheorem{thm}{Theorem}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{claim}[thm]{Claim}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lema}{Lemma}[section]
\newtheorem{alg}{Algorithm}
\newtheorem{asmp}{Assumption}[section]

\theoremstyle{definition}

\newtheorem{example}{Example}
\newtheorem{defn}{Definition}
\newtheorem{rem}{Remark}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\cov}{cov}
%\DeclareMathOperator{\vec}{vec}
\DeclareMathOperator{\vech}{vech}

\DeclareMathOperator{\pr}{Pr}

\newcommand{\X}{\ensuremath{\mathrm{X}}}
\newcommand{\R}{\ensuremath{\mathrm{R}}}
\newcommand{\p}{\ensuremath{\mathrm{P}}}

\newcommand{\aic}{\textsc{aic}}
\newcommand{\bic}{\textsc{bic}}
\newcommand{\brc}{\textsc{brc}}
\newcommand{\cdf}{\textsc{cdf}}
\newcommand{\clt}{\textsc{clt}}
\newcommand{\dd}[1]{\frac{\partial}{\partial #1}}
\newcommand{\dgp}{\textsc{dgp}}
\newcommand{\fclt}{\textsc{fclt}}
\newcommand{\fwe}{\textsc{fwe}}
\newcommand{\gdp}{\textsc{gdp}}
\newcommand{\hac}{\textsc{hac}}
\newcommand{\ma}{\textsc{ma}}
\newcommand{\mds}{\textsc{mds}}
\newcommand{\ned}{\textsc{ned}}
\newcommand{\ols}{\textsc{ols}}
\newcommand{\oos}{\textsc{oos}}
\newcommand{\sfwe}{\textsc{sfwe}}
\newcommand{\spa}{\textsc{spa}}
\newcommand{\wfwe}{\textsc{wfwe}}

\renewcommand{\Re}{\ensuremath{\mathbb{R}}}

\renewcommand{\topfraction}{.85}
\renewcommand{\bottomfraction}{.7}
\renewcommand{\textfraction}{.15}
\renewcommand{\floatpagefraction}{.66}
\renewcommand{\dbltopfraction}{.66}
\renewcommand{\dblfloatpagefraction}{.66}
\setcounter{topnumber}{9}
\setcounter{bottomnumber}{9}
\setcounter{totalnumber}{20}
\setcounter{dbltopnumber}{9}

\begin{document}

\author{Gray Calhoun\thanks{ Economics Department; Iowa State
    University; Ames, IA 50011.  Telephone: (515) 294-6271.  Email:
    \texttt{gcalhoun@iastate.edu}.  Web:
    \texttt{http://www.econ.iastate.edu/$\sim$gcalhoun}.  I'd like to
    thank Helle Bunzel, Todd Clark, Graham Elliott, Yu-Chin Hsu,
    Michael McCracken, Pablo Pincheira, Allan Timmermann, Stephane
    Meng-Feng Yen and participants at the 2011 Midwest Econometrics
    Group meeting for helpful comments and discussions.  I'd also like to thank Amit
    Goyal for providing computer code and data for his 2008
    \textsc{rfs} paper with Ivo
    Welch \citep{GoW:08}.} \\
  Iowa State University}

\title{An asymptotically normal out-of-sample
  test of equal predictive accuracy for nested models} 

\date{December 9, 2011}

\maketitle

\begin{abstract} 
  \noindent This paper proposes a modification of \citepos[\textit{J.
    Econom.}]{ClW:07} adjusted out-of-sample $t$-test.  The
  alternative model is still estimated with a fixed-length rolling
  window, but the benchmark is estimated with a recursive window. The
  resulting statistic is asymptotically normal even when the models
  are nested.  Moreover, the alternative model can be estimated using
  common model selection methods, such as the \aic\ or \bic.  This
  paper also presents a method to compare multiple models
  simultaneously while controlling familywise error, and
  substantially improves existing block bootstrap methods for
  out-of-sample statistics.  This procedure is then used to analyze
  \citepos[\textit{Rev. Finan. Stud.}]{GoW:08} excess returns dataset.

\strut

\noindent Keywords: Forecast Evaluation, Martingale Difference
Sequence, Model Selection, Family-Wise Error Rate; Multiple Testing;
Bootstrap; Reality Check

\strut

\noindent JEL Classification Numbers: C22, C53

\end{abstract}

\newpage 

\section{Introduction} This paper proposes an out-of-sample (\oos)
test statistic that is asymptotically normal with mean zero even when
the models studied are nested.  This paper also proves that common
block bootstrap methods consistently estimate the statistic's
distribution, and shows how the statistic can be used to study many
models simultaneously while maintaining strong control of the
familywise error (\fwe), i.e. ensuring that the probability that the
hypothesis that the model has equal predictive ability to a benchmark
is incorrectly rejected for any of the models is no higher than a
preset level.

\oos\ tests are commonly used in International Macroeconomics,
Macroeconomics, and Finance (see, for example, \citealt{MeR:83};
\citealt{StW:03}; and \citealt{GoW:08}) and there is a substantial
literature developing the theoretical properties of these statistics,
beginning primarily with \citet{DiM:95} and
\citet{Wes:96}.\footnote{Other papers in this literature include
  \citet{WeM:98}, \citet{Mcc:98,Mcc:00},
  \citet{ClM:01,ClM:05-2,ClM:05,ClM:11b,ClM:12,ClM:12b},
  \citet{CCS:01}, \citet{CoS:02,CoS:04,CoS:07}, \citet{Whi:00},
  \citet{InK:04,InK:06}, \citet{Han:05}, \citet{Ros:05},
  \citet{ClW:06,ClW:07}, \citet{Ana:07}, \citet{GiR:09,GiR:10},
  \citet{HuW:10}, \citet{HLN:11}, \cite{InR:11}, \cite{Pin:11},
  \cite{RoS:11,RoS:11b}, and \citet{Cal:11}, among others.  For recent
  reviews of this literature and additional references, see
  \citet{McW:02}, \citet{CoS:06}, \citet{Wes:06}, \citet{ClM:11c},
  \citet{CoD:11}, and \citet{Gia:11}} In a pair of papers,
\citet{ClW:06,ClW:07} develop an \oos\ test of the null hypothesis
that a small benchmark model is correctly specified.  Their test
compares the forecasting performance of a pair of nested models, and
the null hypothesis is that the innovations in the smaller model form
a martingale difference sequence.  This test procedure is popular, and
one assumes that this is due in part to the statistic's convenience,
the statistic is approximately normal after adjusting for the
estimation error of the larger model.  Normality comes from a
fixed-length rolling window, as in \citet{GiW:06}, and the adjustment
centers the statistic appropriately.  This statistic is especially
convenient because other \oos\ tests for similar hypotheses
(\citealt{CCS:01}; \citealt{ClM:01,ClM:05}; \citealt{CoS:02,CoS:04};
and \citealt{Mcc:07}; among others) have a nonstandard limit
distribution and place restrictions on the models under consideration,
while other asymptotically normal statistics test a different null
hypothesis \citep{GiW:06} or place assumptions on the models and \dgp\
that are often violated in empirical work (\citealt{DiM:95};
\citealt{Wes:96}; \citealt{WeM:98};
\citealt{Mcc:00}).\footnote{\citet{DiM:95} assume that the models are
  not estimated. \citet{Wes:96}, \citet{WeM:98}, and \citet{Mcc:00}
  implicitly assume that the models do not converge to the same limit,
  which rules out nesting.}

However, Clark and West's statistic is only ``approximately normal''
in an informal sense.  Clark and West present Monte Carlo evidence of
the statistic's distribution, but only prove that the statistic is
asymptotically normal with mean zero when the benchmark model is a
random walk \citep{ClW:06}. Estimating the parameters of the smaller
model invalidates their proof.

In this paper, I show that a modified version of their statistic is
asymptotically normal even when the smaller model is estimated.  To
achieve normality, we need a consistent estimate of the pseudo-true
benchmark model, while maintaining an inconsistent estimate of the
larger model so that we can ignore nesting.  We can meet both needs by
using different window strategies for each model: the benchmark model
is estimated using a recursive window and the alternative with a
fixed-length rolling window.

Mixing window strategies is uncommon but needn't be. In most
applications, the null hypothesis imposes stability as well as equal
accuracy between the two models.  The benchmark model rarely allows
for breaks, parameter drift, or other forms of
instability,\footnote{Exceptions are \citepos{StW:07}
  \textsc{ima}(1,1) and \textsc{uc-sv} models of inflation.} but the
researcher is typically concerned about instability.  Indeed, concern
about instability is often given as a reason for doing an \oos\
analysis, especially with a short rolling window.\footnote{This
  motivation is discussed by \citet{StW:03}, \citet{PeT:05,PeT:07},
  \cite{GiW:06}, \citet{GoW:08}, \citet{ClM:09c}, and
  \cite{GiR:09,GiR:10}, among others.} A researcher could impose
stability on both models by using a recursive window or relax
stability for both by using a rolling window; either approach should
not affect the test's size, but may affect power.  But the researcher
could instead impose stability on the benchmark and relax it for the
alternative by using a recursive window for the benchmark and a
rolling window for the alternative model.  This approach could have a
power advantage and is similar in spirit to using a Likelihood Ratio
Test instead of an \textsc{lm} or Wald test, which depend on just the
restricted or unrestricted model respectively.  Simulations presented
in Section~\ref{sec:2} show that this approach gives a substantial
power advantage when there are breaks.

This paper's statistic has a substantial advantage over existing \oos\
tests for nested models: the alternative can be essentially arbitrary
as long as high level moment conditions hold.  In particular,
researchers can use model selection techniques like the \aic\ or \bic\
to determine the number of lags to include, the particular exogenous
variables to include, etc.  Other methods that test a similar
hypothesis are unable to handle these models \citep[except][which does
not allow the benchmark to be estimated]{ClW:06}; \citet{GiW:06} are
able to handle such models for both the alternative and the benchmark
but, as mentioned earlier, they test a different aspect of forecasting
performance.

This paper focuses on nested models, as they have received the most
attention in the empirical and theoretical literature, but the
statistic can be used with non-nested models as well.  This generality
is useful, since \citepos{Wes:96} results do not apply to non-nested
models if they both encompass the true \dgp,\footnote{\citet{ClM:11b}
  call this scenario, ``overlapping models.''} which is allowable
under the null: in the limit, both models will converge to the \dgp\
and give identical forecasts.  Consequently, the naive \oos\ $t$-test
is invalid, even after correcting the standard error if necessary to
reflect parameter uncertainty.  \citet{ClM:11b} show that the fixed
window \oos\ $t$-test remains normal for these models but the
recursive and rolling windows (with the window size increasing to
$\infty$) do not, and provide a procedure for pointwise (but not
uniformly) valid tests for the recursive and rolling windows and
uniformly valid tests for the fixed window.  The test proposed in this
paper is uniformly valid and places fewer assumptions on the models
under study and the true \dgp.

Since researchers often have a set of potential models and want to
know which of them significantly outperform the benchmark, procedures
that compare a single pair of models are of limited practical value.
As \citet{Whi:00} demonstrates, looking at the naive $p$-values of
individual tests is misleading, but researchers can get a valid test
by using the bootstrap to approximate the distribution of the largest
individual test statistic under the null (White calls this procedure
the \textit{Bootstrap Reality Check} or \brc).  This paper presents a test
for equal predictive ability of multiple models based on
\citepos{RoW:05} StepM, which uses a step-down procedure that
iteratively rejects models to achieve higher power than the \brc\ and
indicate which of the models improves on the benchmark (see
Theorem~\ref{res:2} for details).

This paper also presents a new result for the validity of block
bootstraps with \oos\ statistics, which is necessary to verify that
the StepM is valid.  Existing results on bootstrapping \oos\
statistics have some drawbacks.  \citet{Whi:00} and \citet{Han:05} use
the stationary bootstrap, but require the test sample to be much
smaller than the training sample, which obviously does not hold here.
\citet{CoS:07} relax that requirement, but make the statistic more
complicated than necessary by adjusting the objective function of the
bootstrapped statistic to center it correctly.\footnote{Their
  recentering is required for consistency and does not imply higher
  order accuracy.}  A parametric bootstrap, such as that used by
\cite{Mar:95}, \cite{Lut:99}, and \citet{ClM:12b}, is an alternative
method, but requires the benchmark model to be correctly specified.
Although I focus on the null hypothesis that the benchmark is
correctly specified, this paper's block bootstrap methods remain valid
when the benchmark is misspecified and are relatively easy to
implement.  So this paper's result for bootstrapping \oos\ statistics
considerably improves on existing procedures.

The next section presents our new statistics and Section~\ref{sec:1b}
our block bootstrap result.  Section~\ref{sec:2} presents two
simulations that compare our pairwise \oos\ test to \poscw\ original
statistic.  Section~\ref{sec:3} demonstrates the use of our statistic
by reanalyzing \citepos{GoW:08} study of excess return
predictability. Section~\ref{sec:4} concludes.

\section{Out-of-Sample Model Comparisons}\label{sec:1}
This section presents the new \oos\ statistic.  I'll present the
single-comparison statistic first and then extend it to multiple
comparisons.  Suppose for now that a researcher is interested in
predicting the target variable $y_{t+1}$ with a vector of regressors
$x_t$; also let $v_t$ be another random process and suppose that
$(y_t, x_t, v_t)$ is stationary and weakly dependent
(Theorem~\ref{res:1} lists the assumptions formally).  In addition,
let $\beta_0 = (\E x_t x_t')^{-1} \E x_t y_{t+1}$ be the pseudo-true
coefficient of the regression of $y_{t+1}$ on $x_t$ and define
$\varepsilon_{t+1} = y_{t+1} - x_t'\beta_0$.  If the linear model is
correctly specified, so $\varepsilon_{t+1}$ is a martingale difference
sequence with respect to $\mathcal{F}_t \equiv \sigma((x_t, v_t, y_t),
(x_{t-1}, v_{t-1}, y_{t-1}),\dots)$, then we can see immediately that
\begin{equation}
  \label{eq:4}
  \tfrac{1}{\sqrt{P}} \sum_{t=R+1}^T \varepsilon_{t+1} (v_t - x_t'\beta_0)
\end{equation}
obeys an \mds\ \clt\ (assuming that its variance is uniformly
positive) and is asymptotically normal as $P \to \infty$, with $R$ an
arbitrary starting value\footnote{It will be clear momentarily why the
  summation begins at $R+1$ instead of $1$.} and $P = T - R$.
Straightforward algebra \citep{ClW:07} shows that
\begin{equation}
  \label{eq:5}
  \tfrac{2}{\sqrt{P}} \sum_{t=R+1}^T \varepsilon_{t+1} (v_t -
  x_t'\beta_0) = \tfrac{1}{\sqrt{P}} \sum_{t=R+1}^T \Big[(y_{t+1} - 
  x_t\beta_0)^2 - (y_{t+1} - v_t)^2 + (x_t'\beta_0 - v_t)^2 \Big].
\end{equation}

\citet{ClW:06,ClW:07} base their \oos\ statistic on the right side
of~\eqref{eq:5}, where $R$ is the size of the training sample and $P$
the size of the test sample used to evaluate the forecasting models.
\citet{ClW:06} use a second forecast $\hat{y}_{t+1}$ as $v_t$.  They
use a rolling window of length $R$ (i.e., $\hat{y}_{t+1}$ is a
function of $y_t, x_{t-1}, z_{t-1} \dots, y_{t-R+1}, x_{t-R}$ and
$z_{t-R}$ where $z_t$ is another weakly dependent random process),
which is kept finite as $T \to \infty$, so $\hat{y}_{t+1}$ inherits
the weak dependence properties of the variables used to estimate it.
Keeping $R$ finite ensures that the conditional variance remains
positive, so the sum obeys a \clt.  This method of ensuring normality
was introduced by \citet{GiW:06}.  The coefficients $\beta_0$ are
assumed to be zero so $\varepsilon_{t+1}$ is observed directly (under
the null hypothesis) and Clark and West propose using this statistic
to test the null that $\varepsilon_{t+1}$ is an \mds\ with respect to
$\mathcal{F}_t$.  In \citet{ClW:07}, $\beta_0$ is unknown but is
estimated with a fixed-length rolling window as well, so
\begin{equation*}
  \tilde{\beta}_t = \Big(\sum_{s=t-R+1}^t x_{t-1} x_{t-1}'\Big)^{-1}
  \sum_{s=t-R+1}^t x_{t-1} y_t
\end{equation*}
and $\hat{\varepsilon}_{t+1} = y_{t+1} - x_t'\tilde{\beta}_t$ replaces
$\varepsilon_{t+1}$ in the test statistic for \mds.  Unfortunately,
$\hat{\varepsilon}_{t+1}$ is not an \mds\ even when
$\varepsilon_{t+1}$ is, so the statistic is no longer asymptotically
mean-zero normal, even though this approximation performs well in the
simulations reported by \citet{ClW:07}.

This paper proposes using the same basic \oos\ statistic, 
but using a recursive window to estimate $\beta_0$ and produce
$\hat{\varepsilon}_{t+1}$; i.e.
\begin{equation}
  \label{eq:8}
  \hat{\beta}_t = \Big(\sum_{s=2}^{t} x_{t-1} x_{t-1}'\Big)^{-1}
  \sum_{s=2}^t x_{t-1} y_t.
\end{equation}
\citepos{Wes:96} Theorem 4.1 implies that
\begin{equation*}
  \tfrac{1}{\sqrt{P}} \sum_{t=R+1}^T \Big[(y_{t+1} -
  x_t\hat{\beta}_t)^2 - (y_{t+1} - v_t)^2 + (x_t'\hat{\beta}_t - v_t)^2 \Big]
\end{equation*}
is asymptotically normal with mean zero under the null for fairly
arbitrary processes $v_t$, as long as $v_t$ is weakly dependent and
the \oos\ statistic has uniformly positive variance.  Just as in
\citet{ClW:06}, these conditions are ensured if $v_t$ is another
forecast of $y_{t+1}$ based on a fixed length rolling window.
Theorem~\ref{res:1} presents the details of this result.  The
assumptions required are essentially the same in existing papers
(e.g. \citealp{Wes:96}; \citealp{WeM:98}; \citealp{Mcc:00};
\citealp{GiW:06}; and \citealp{ClW:06,ClW:07}).  Please see the
original papers for a discussion of these assumptions.

\begin{thm}\label{res:1}
  Suppose that we have two models $\hat{y}_{0t}$ and $\hat{y}_{1t}$ to
  forecast the variable $y_t$, and have observations for
  $t=1,\dots,T+1$.  Assume the following hold:
  \begin{enumerate}
  \item \label{item:1} The benchmark forecast $\hat{y}_{0,t+1}$, is
    estimated using \textsl{\ols} with a recursive window:
    $\hat{y}_{0,t+1} = x_t'\hat{\beta}_t$ for some vector of
    predictors $x_t$ with $\hat{\beta}_t$ given by
    Equation~\eqref{eq:8}.  Also define $\beta_0 = (\E x_{t-1}
    x_{t-1}')^{-1} \E x_{t-1} y_t$ and assume that $\beta_0$ does not depend
    on~$t$.
  \item \label{item:2} The alternative forecast, $\hat{y}_{1t}$, is
    estimated using a rolling window of fixed length $R$ (which is
    less than $T$), so $\hat{y}_{1,t+1} =
    \psi(y_t,z_t,\dots,y_{t-R+1}, z_{t-R+1})$ where $\psi$ is a known
    function and $z_t$ is a sequence of predictors that may include
    $x_t$.
  \item \label{item:3} The series $y_t$ and $z_t$ are \textsl{\ned} of size
    $-\frac12$ on a strong mixing series of size $-\frac{r}{r-2}$ for $r>2$ or a
    uniform mixing series of size $-\frac{r}{2r-2}$.  Also, $y_t$,
    $\hat{y}_{1t}$, and $x_t$ have uniformly bounded $2 r+\delta$
    moments for some positive $\delta$.
  \item \label{item:4} Define \[f_t(\beta) = (y_{t+1} - x_t'\beta)^2 -
    (y_{t+1} - \hat{y}_{1,t+1})^2 + (x_t'\beta - \hat{y}_{1,t+1})^2,\]
    $\bar{f}(\beta) = \tfrac1P \sum_{t=R+1}^T f_t(\beta)$, and $\bar f
    = \tfrac1P \sum_{t=R+1}^{T} f_t(\hat{\beta}_t)$, with $P = T - R$;
    $\bar f(\beta_0)$ has uniformly positive and finite long run
    variance.
  \end{enumerate}
  Under the null hypothesis that $y_t - \hat{y}_{0t}(\beta_0)$ is a
  martingale difference sequence with respect to the filtration
  $\mathcal{F}_t = \sigma((y_t, z_{t}), (y_{t-1}, z_{t-1}),\dots)$,
  $\tfrac{\sqrt{P}}{\hat\sigma} \bar f \to^d N(0,1)$, where 
  \begin{align*}
    \hat{\sigma}^2 &= \hat{S}_{ff} + 2 \Pi (\hat{S}_{fg} + \hat{S}_{gg}), &
    \hat{S}_{ff} &= \tfrac1P \sum_{t=R+1}^T (f_t(\hat{\beta}_t) - \bar
    f)^2, \\
    \hat{S}_{fg} &= \tfrac1P \sum_{t=R+1}^T (f_t(\hat{\beta}_t) -
    \bar{f})(g_t(\hat{\beta}_t) - \bar g)', &
    \hat{S}_{gg} &= \tfrac1P \sum_{t=R+1}^T (g_t(\hat{\beta}_t) - \bar
    g)(g_t(\hat{\beta}_t) - \bar g)',
  \end{align*}
  $\Pi = 1 - \tfrac{R}{P} \log(1 + \tfrac{P}{R})$, $\bar{g} = \tfrac1T
  \sum_{t=R+1}^T g_t(\hat{\beta}_t)$, $\X' = [x_1,\dots,x_T]$, and
  \begin{equation*}
    g_t(\beta) =
    \Big\{\tfrac{2}{P}\sum_{s=R}^T x_s (x_s'\beta - \hat{y}_{1,s+1}) \Big\}'
    \big(\tfrac1T \X'\X \big)^{-1} x_t(y_{t+1} - x_t'\beta).
  \end{equation*}
\end{thm}

The following remarks are relevant to Theorem~\ref{res:1}:

\begin{rem}
  Forecasters will be interested in the one-sided alternative that $\E
  f_t(\beta_0) > 0$; i.e. that the alternative model is expected to
  forecast better than the benchmark.
\end{rem}

\begin{rem}
  These results are presented for one-period-ahead forecasting for
  simplicity.  They can be extended to forecasting at a longer horizon
  by appropriately modifying the variance-covariance matrix to account
  for the correlation structure of the forecast errors. (i.e. for
  $\tau$-step-ahead forecasts the errors will be an \ma($\tau-1$) process).
\end{rem}

\begin{rem}
  The requirement that the asymptotic variance of $\bar f(\beta_0)$ be
  uniformly positive is much less restrictive than in \cite{Wes:96}.
  As in \cite{GiW:06} and \citet{ClW:06,ClW:07}, the assumption only
  serves to rule out pathological cases---for example, letting both
  the benchmark and the alternative model be white noise. In
  \citet{Wes:96}, this assumption is a restriction on the \dgp\ as
  well as the forecasting models, but in this paper it is a
  restriction only on the models.
\end{rem}

\begin{rem}
  As in \citet{Wes:96}, $\Pi \to 1$ as $T \to \infty$ since $R$ is
  fixed.  But using West's general formula for $\Pi$ (which holds when
  $\lim \tfrac{P}{R} \in [0,\infty]$) can improve the statistic in practice,
  since researchers often invoke ``fixed $R$'' asymptotics when $R$ is
  large.  Section~\ref{sec:2} shows via Monte Carlo that this
  approximation can be accurate even when $R$ and $P$ are equal.
\end{rem}

\begin{rem}
  If one wants to test the less restrictive null hypothesis that
  $y_{t} - \hat{y}_{0t}$ is uncorrelated with $\hat{y}_{1t}$ but not
  necessarily an \mds, one can replace $\hat{S}_{ff}$, $\hat{S}_{fg}$
  and $\hat{S}_{gg}$ with their \hac\ counterparts.
  Lemma~\ref{res:a5} presents a more general version of the theorem
  that can cover this case.
\end{rem}

\begin{rem}
  The statistic we present tests the null hypothesis that the forecast
  errors from the population version of the benchmark model are a
  martingale difference sequence.  This hypothesis may not be
  appropriate, depending on the loss function or utility function of
  interest.  Our statistic can be modified to test implications of
  optimal forecasts under other loss functions
  \citep[see][]{PaT:07,PaT:07b}; the statistic should be expressed as
  a forecast encompassing test using the models' generalized forecast
  errors.\footnote{See \citet{HLN:98} and \citet[Section~4]{ClW:07}.}
  Again, Lemma~\ref{res:a5} can cover these other applications.
\end{rem}

\begin{rem}
  \citet{GiW:06} and \citet{ClW:06,ClW:07} emphasize the rolling
  window but claim that their results hold for a fixed-length fixed
  window as well, where the unknown coefficients are estimated only
  once using the first $R$ observations.  This claim is true but not
  obviously so.  The proof for the rolling window is based on the idea
  that the forecast errors are weakly dependent because they are a
  function of a finite number of consecutive weakly dependent
  observations.  But using a fixed window introduces another source of
  dependence, all of the forecasts depend on the same coefficient
  estimates.  One can prove that their results apply to fixed window
  forecasts by using a coupling argument similar to \citepos{Cal:11}.
  Interested readers should refer to \citet{Cal:11} for the argument
  and to \citet{MeP:02} for a review of the necessary coupling
  results.  Theorem~\ref{res:1} can be shown to hold when $\hat
  y_{1t}$ is estimated with a fixed-length fixed window using the same
  arguments.
\end{rem}

Since most empirical papers study more than one alternative model,
Theorem~\ref{sec:1} is of limited use on its own.\footnote{Moreover,
  we would need to account for the existence of multiple models even if
each paper considers a single model, since there are many papers
studying the same data.}  It can, however, be
used as the basis for a procedure that allows researchers to make
multiple comparisons.  Before presenting a theoretical result, I'll
discuss some issues related to multiple hypothesis testing.

Suppose we have the family of hypotheses, $H_1,\dots,H_J$.  It is
clear that testing each hypothesis individually will often have a
probability greater than the tests' nominal size of rejecting at least
once.\footnote{Unless the statistics used for each test are completely
  interdependent, the probability will be strictly greater than the
  nominal size.}  Econometricians, e.g. \citet{Whi:00},
\citet{Han:05}, \cite{HuW:10}, and \citet{ClM:12b}, have emphasized
statistics that test families of hypotheses that control the
probability any hypothesis is rejected given that they all are true,
known as \textit{weak control of familywise error}
(\wfwe).\footnote{An exception is \citet{HHK:10} who combine
  \citepos{RoW:05} StepM with \citepos{Han:05} threshold rule to
  control \sfwe\ for certain families of one-sided tests.}  This paper
focuses instead on controlling the probability that at least one true
hypothesis is rejected given any combination of true and false
hypotheses, known as \textit{strong control of familywise error}
(\sfwe).  For most empirical work, \sfwe\ is desired; fortunately,
even though the papers only prove \wfwe, statistics based on
nonparametric block bootstraps \citep{Whi:00,Han:05} can be shown to
control \sfwe\ as well \citep[this follows directly from][]{RoW:05}
and those based on the parametric bootstrap \citep{ClM:12b} essentially
control \sfwe\ if the individual null hypotheses are strengthened
slightly as below (see Part~(\ref{it:1}) of Theorem~\ref{res:2} as
well as Remark~\ref{rem:2}).  \citet{HuW:10} propose that researchers
construct critical values from the asymptotic joint distribution of
the test statistics and can control \sfwe\ as long as there is a
consistent estimator of that distribution.

Only tests with \sfwe\ can tell researchers which of the hypotheses
are false.  To see why, imagine that there are only two hypotheses:
$H_1$ is true and $H_2$ is false.  A test that rejects the true
hypothesis, $H_1$, with arbitrarily high probability still can satisfy
\wfwe: since not all of the hypotheses are true, the behavior of tests
with weak control is essentially unconstrained.  Such a test would not
satisfy \sfwe, though.  For \sfwe\ in this setting, a test must reject
$H_1$ with probability at most $\alpha$ (letting $\alpha$ be the
desired level of control).  In most research, we would view rejection
of the true hypothesis $H_1$ as a mistake.


This paper uses \citepos{RoW:05} StepM procedure, which is an iterated
extension of \citepos{Whi:00} Reality Check designed to reject as many
false hypotheses as possible while achieving \sfwe.  Their method
relies on the bootstrap to estimate the joint dependence between the
test statistic associated with each model.  The bootstrap used in this
paper is new, and is outlined in Algorithm~\ref{alg:1}.
Algorithm~\ref{alg:1} actually presents a more general version of the
bootstrap that remains valid with a misspecified benchmark model.
Imposing the null hypothesis of \mds\ leads to simpler version that
will be discussed later.
\begin{alg}\label{alg:1}
  Suppose that there are $m$ alternative forecasting models,
  $\hat{y}_{1t},\dots, \hat{y}_{mt}$, and define the data matrices
  $\X_\R = (X_1,\dots,X_R)'$ and $\X_{\p} = (X_{R+1},\dots,X_{T-1})$
  with
  \begin{equation*}
    X_t = \begin{cases}
      (y_{t+1}, x_t')' & t \leq R \\
      (y_{t+1}, x_t', \hat{y}_{1,t+1}, \dots, \hat{y}_{m,t+1})' & t > R.
    \end{cases}
  \end{equation*}
  \begin{enumerate}
  \item Draw $B$ samples of $P$ observations from $\X_{\p}$ using the
    moving or circular blocks bootstrap with block length $b$ or the
    stationary bootstrap with geometric block lengths with success
    probability $p$.  Denote each sample as $\X_{\p, l}^{*}$ and let
    $\X_l^{*} = [\X_{\R}', \X_{\p,l}^{*\prime}]'$.
  \item Estimate $\bar{f}^{*}_{li}$ and $\hat{\sigma}_{li}^{*}$ as in
    Theorem~\ref{res:1} for each bootstrap sample, $\X^{*}_l$, and each
    alternative model, $\hat{y}_{it}$.
  \end{enumerate}
\end{alg}

This procedure exploits the fact that $R$ is finite in
Theorem~\ref{res:1} and that the expected block length will grow with
$T$.  Under these asymptotics, a growing proportion of the
rolling-window forecasts are the same if we bootstrap the forecasts as
if we bootstrap the empirical data and reestimate the models.
Bootstrapping the forecasts makes the computations faster and easier,
but requires us to drop the first $R$ observations from the bootstrap
(the alternative forecasts are not defined for the first $R$
observations).  I add those observations to the beginning of each
bootstrap sample so that population means under the bootstrap-induced
probability distribution equal sample means.  The benchmark model
still needs to be reestimated in each bootstrap sample.

Theorem~\ref{res:2} presents the final procedure.

\begin{thm}\label{res:2}
  Suppose the conditions of Lemma~\ref{res:1} hold, with assumptions
  on the alternative model, $\hat{y}_{1t}$, holding for each of the
  $m$ models $\hat{y}_{1t}, \dots, \hat{y}_{mt}$ and let the subscript
  $l$ denote the different quantities associated with $\hat{y}_{lt}$
  (i.e. $\mathcal{F}_{lt}$, etc.)  Also assume that the long-run
  variance-covariance matrix of the vector
  $(\bar{f}_1(\beta_0),\dots,\bar{f}_m(\beta_0))'$ is uniformly
  positive definite.

  Let the $*$-superscript denote a random variable with the
  distribution induced by the bootstrap of Algorithm~\ref{alg:1} and
  consider the following procedure:
  \begin{enumerate}
  \item Define $M_0 = \emptyset$ and, for $j = 1,\dots,m$, let $M_j =
    \{i : \tfrac1{\hat\sigma_i} \bar{f}_{i} > \hat{d}_j\}$, where
    $\hat{d}_j$ is the $1-\alpha$ quantile of $\max_{i \notin M_{j-1}}
    \tfrac{1}{\hat{\sigma}_i^{*}}(\bar{f}_{i}^{*} -
    \bar{f_i}(\hat{\beta}_{T+1}))$.
  \item Reject all of the models $i$ with $i \in \bigcup_{j=1}^m M_j$.
  \end{enumerate}
  The following conclusions hold:
  \begin{enumerate}[i.]
  \item\label{it:1} For each $G \subset \{1,\dots,m\}$, let
    $\mathcal{F}_t^G$ be the smallest $\sigma$-field containing
    $\mathcal{F}_{lt}$ for all $l \in G$.  Under the null hypothesis
    that $y_t - \hat{y}_{0t}$ is an \textsl{\mds} with respect to
    $\mathcal{F}_t^I$ for some $I \subset \{1,\dots,m\}$, the
    procedure outlined above, but using the moving block bootstrap
    with block length $1$, has probability at most $\alpha$ of
    rejecting one or more models in $I$.
  \item\label{it:2} Let $H_l$ be the null hypothesis that $y_t -
    \hat{y}_{0t}$ is an \textsl{\mds} with respect to
    $\mathcal{F}_{lt}$ against the one-sided alternative $\E \bar
    f_i(\beta_0) > 0$.  If $p \to 0$ and $P p \to \infty$ as $T \to
    \infty$ (for the stationary bootstrap) or $b \to \infty$ and
    $\frac{b}{P} \to 0$ (for the moving or circular block bootstraps)
    then the procedure outlined above controls \textsl{\sfwe} at level
    $\alpha$ for the family of null hypotheses $H_1,\dots,H_m$.
  \item\label{it:3} Let $H_l$ be the null hypothesis that $y_t -
    \hat{y}_{0t}$ is uncorrelated with $\hat{y}_{lt}$ against the
    one-sided alternative $\E \bar f_i(\beta_0) > 0$.  If $p \to 0$
    and $P p \to \infty$ as $T \to \infty$ (for the stationary
    bootstrap) or $b \to \infty$ and $\frac{b}{P} \to 0$ (for the
    moving or circular block bootstraps) then the procedure outlined
    above controls \textsl{\sfwe} at level $\alpha$ for the family of
    null hypotheses $H_1,\dots,H_m$.
  \end{enumerate}
\end{thm}

The following remarks apply to Theorem~\ref{res:2}.

\begin{rem}
It is worth emphasizing that this procedure is very easy to use under
the null hypothesis of correct specification (Part~\ref{it:1}).  The
researcher can use a standard estimate of the statistic's asymptotic
variance (not a \hac\ estimator) and an i.i.d. bootstrap.  Even
better, the alternative forecasts only need to be estimated once,
before the bootstrap.
\end{rem}

\begin{rem}\label{rem:2}
  The key difference between Parts~(\ref{it:1}) and~(\ref{it:2}) is
  that, in Part~(\ref{it:2}), the forecast error is an \mds\ with
  respect to several individual series, but not necessarily with
  respect to the pooled information set generated by all of those
  series together.\footnote{It is straightforward to construct three
    series, $u_t$, $v_t$, and $w_t$, such that $w_t$ is an \mds\ with
    respect to $\sigma((u_t, w_t), (u_{t-1}, w_{t-1}),\dots)$ and
    $\sigma((v_t, w_t), (v_{t-1}, w_{t-1}),\dots)$ but not
    $\sigma((u_t, v_t, w_t), (u_{t-1}, v_{t-1}, w_{t-1}),\dots)$.
    This is essentially the scenario imposed in Part~(\ref{it:2}).}
  Using $b = 1$ would consistently estimate the marginal distribution
  of each $\tfrac1{\sigma_i} \bar{f}_i$ under this weaker null
  hypothesis, but would not necessarily estimate the joint
  distribution of two or more of those terms correctly (in particular,
  the covariance could be wrong).  The stronger null hypothesis
  imposed in Part~\ref{it:1} ensures that resampling with $b = 1$
  estimates the joint distribution correctly as well.

  The same reasoning implies that a parametric bootstrap
  \citep[i.e.][]{ClM:12b} achieves control of \sfwe\ only under the
  stronger hypotheses of Part~(\ref{it:1}).  Fortunately,
  Part~(\ref{it:1}) seems to capture the goals of most empirical work,
  so researchers can make use of the considerable simplifications that
  occur in that setting.
\end{rem}

\begin{rem}
  If calculating $\hat{\sigma}_i$ is burdensome, one can do the same
  bootstrap without studentizing the statistics.  This procedure is
  likely to have worse size and power properties, but may be more
  convenient.  One could also estimate the variance with a second
  bootstrap step, but execution might take too long to be practical,
  or use a convenient but inconsistent approximation of the variance.
  The estimator of the variance in Part~\ref{it:3} should have the
  best performance if it is \hac\ \cite[the results of][may be
  relevant]{GoK:96}, but that is not necessary for validity.
  See \citet{Han:05} and \citet[Section~4.2]{RoW:05} for a discussion
  of the benefits of studentization.
\end{rem}

\begin{rem}
  If the number of alternative models is large, controlling the \fwe\
  may be too strict a criterion.  \citet{RSW:08} discuss procedures to
  control criteria other than the \fwe, and one can use their
  generalizations of the StepM procedure here as well.
\end{rem}

\begin{rem}\label{rem:01}
  \citet{Pin:11} raises the issue that, since there are often several
  models that could be used as the benchmark, researchers may want to
  control for data snooping over the null hypotheses as well as the
  alternatives.  For example, one could use either \citepos{AtO:01}
  random walk or \citepos{StW:07} \textsc{ima}(1,1) as benchmark
  inflation models, so it might make sense to require an alternative
  model to outperform them both.\footnote{\citet{Pin:11} studies tests
    that reject if the alternative model outperforms either of the
    models, so the details are somewhat different in our papers.}
  Allowing multiple benchmark models can be expressed as an
  Intersection-Union test, so Theorem~\ref{res:2}'s procedure
  (Part~(\ref{it:3})) easily accommodates this extension by taking
  each $\bar f_i$ and $\hat{\sigma}_{i}^{2}$ to be a random
  $q$-vector;\footnote{If a researcher uses multiple benchmark models,
    it would be a mistake to assume that they are all correctly
    specified, so only the null hypothesis of Part~(\ref{it:3}) is
    appropriate.} the first element of $\bar f_{i}$, written as $\bar
  f_{i1}$, compares the first benchmark model to the $i$th alternative
  and the first element of $\hat{\sigma}_i^2$ is the corresponding
  estimate of asymptotic variance, the second element corresponds to
  the second benchmark model, etc.

  Steps 1 and 2 of Theorem~\ref{res:2}'s procedure now become:
  \begin{enumerate}
  \item Define $M_0 = \emptyset$ and, for $j = 1,\dots,m$, let $M_j =
    \{(i,k): \tfrac1{\hat\sigma_{ik}} |\bar{f}_{ik}| > \hat{d}_j\}$,
    where $\hat{d}_j$ is the $1-2 \alpha$ quantile of $\max_{(i,k)
      \notin M_{j-1}} \tfrac1{\hat\sigma_{ik}^*} |\bar{f}_{ik}^{*} -
    \bar{f}_{ik}(\hat{\beta}_{k,T+1})|$.
  \item Reject all of the hypotheses $H_i$ such that $(i,k) \in
    \bigcup_{j=1}^m M_j$ for all $k$.
  \end{enumerate}
  Also note that the asymptotic variance-covariance matrix of each
  $\bar f_i$ does not need to be positive definite as long as the
  variance of each of its elements is positive.  A formal statement of
  this result is given in Appendix~\ref{sec:B}.
\end{rem}

\section{The Bootstrap for Out-of-Sample Statistics}\label{sec:1b}
The validity of the bootstrap in Theorem~\ref{res:2} is a special case
of a result of independent interest---the validity in general of block
bootstraps for asymptotically normal \oos\ statistics.  This section
presents the general result.  In this section, let $\to^{p^{*}}$ and
$\to^{d^{*}}$ refer to convergence in probability or distribution
conditional on the observed data.  Similarly, $\E^{*}$, $\var^{*}$,
and $\cov^{*}$ refer to the expectation, variance, and covariance with
respect to the probability measure induced by the bootstrap, and
$y_t^{*}$, etc. is the random variable $y_t$ but under the
bootstrap-induced \cdf.

The notation in this section is more general than that of
Section~\ref{sec:1}.  The assumptions required are generalizations of
the conditions of Theorems~\ref{res:1} and~\ref{res:2}.  See
\citet{Wes:96,Wes:06}, \citet{WeM:98}, and \citet{Mcc:00} for a
discussion of these conditions, as theirs are nearly identical.
Theorem~\ref{res:3} gives the result.

\begin{thm}\label{res:3}
  Suppose the following conditions hold:
  \begin{enumerate}
  \item Let $\{y_t, z_t\}$ be an $L_2$-\textsl{\ned} process of size $-\frac12$ on
    a strong mixing series $\{V_t\}$ of size $-\frac{r}{r-2}$, with $r
    > 2$.
  \item The estimator $\hat{\beta}_t$ of $\beta_0$ is estimated with a
    recursive, rolling, or fixed estimation window and satisfies
    $\hat{\beta}_{t} - \beta_{0} = \hat{B}_{t} H_t$; $\hat{B}_{t}$ is
    a sequence of $k$ by $q$ matrices such that $\sup_t |\hat{B}_t -
    B| \to^p 0$, $\sup_t |\hat{B}_t^{*} - B^{*}| \to^p 0$, and $B^{*}
    = B + o_p$; $H_{t}$ is a sequence of $q$-vectors such that 
    \begin{equation}
      H_{t} = \begin{cases} 
        \tfrac1t \sum_{s=1}^t h_{s} & \text{recursive window} \\
        \tfrac1R \sum_{s=t-R+1}^t h_{s} & \text{rolling window} \\
        \tfrac1R \sum_{s=1}^R h_{s} & \text{fixed window} \\
      \end{cases}
    \end{equation}
    $h_{s}(\beta) = h(y_{s}, z_{s}, \beta)$, $h_s = h_s(\beta_0)$, and
    $\E h_{s} = 0$ for all $s$.
  \item Let $f_{t}(\beta) = f(y_{t}, z_{t}, \beta)$ be an $l$-vector;
    $\| \sup_{\beta \in N} f_{t}(\beta) \|_{r+\delta}$ and $\|
    \sup_{\beta \in N} h_{t}(\beta) \|_{r+\delta}$ are uniformly
    finite in $t$, where $N$ is an open neighborhood of $\beta_{0}$.
  \item Each element of $\E f_{t}(\beta)$ is continuously
    differentiable in the neighborhood $N$.  Moreover, $\sup_{\beta
      \in N} | F_{t}(\beta) |$ is uniformly finite in $t$ with
    $F_{t}(\beta) = \dd{\beta'} \E f_{t}(\beta)$.
  \item There exist finite constants $C$, $\phi > 0$, and $Q \geq r$
    such that \[\sup_{\epsilon : N(\beta_{0}, \epsilon) \subset N}\|
    \sup_{\beta \in N(\beta_{0}, \epsilon)} f_{t}(\beta) - f_{t} \|_Q
    \leq C \epsilon^{\phi}\] and \[\sup_{\epsilon : N(\beta_{0},
      \epsilon) \subset N}\| \sup_{\beta \in N(\beta_{0}, \epsilon)}
    h_{t}(\beta) - h_{t} \|_Q \leq C \epsilon^{\phi},\] where
    $N(\beta, \epsilon) = \{b : |b - \beta| < \epsilon\}$.
  \item $R, P \to \infty$ as $T \to \infty$.
  \item $X_1^{*},\dots,X_T^{*}$ are generated by the moving blocks,
    circular blocks, or stationary bootstrap with block lengths drawn
    from the geometric distribution, and $b$ satisfies $b \to \infty$
    and $\frac{b}{P} \to 0$; $b$ is the block length of the moving or
    circular blocks bootstraps and is the expected block length of the
    stationary bootstrap.
  \item The asymptotic variance matrix of $\bar{f}(\beta_0)$ is
    uniformly positive definite and $\E f_t(\beta_0) = \E
    f_s(\beta_0)$ for all $s$ and $t$.
  \end{enumerate}
  Then
  \begin{equation}
    \pr[\sup_x | \pr^*[\sqrt{P} (\bar{f}^* - \bar{f}(\hat{\beta}_{T+1}))
        \leq x] - \pr[\sqrt{P}( \bar{f} - \E \bar{f}(\beta_0)) \leq x] | >
      \epsilon] \to 0
  \end{equation}
  for all $\epsilon > 0$.
\end{thm}

\begin{rem}
  \citet{Whi:00} and \citet{Han:05} resample the forecasts but do not
  reestimate any of them which requires the additional assumption that
  $\tfrac{P}{R} \log \log R \to 0$ or that the forecasts themselves
  have no estimated parameters.\footnote{\citet{Whi:00} lists several
    different sets of assumptions that give the same result, but these
    seem to be the most general.}
\end{rem}

\begin{rem}
  \citet{CoS:07} use the distribution of $\sqrt{P}(\bar{f}^{*} -
  \bar{f})$ to approximate that of $\sqrt{P}(\bar{f} - \E
  \bar{f}(\beta_0))$.  But it is clear that
  $\bar{f}(\hat{\beta}_{T+1})$ is the bootstrap analogue of $\E
  \bar{f}(\beta_0)$, the parameter of interest.  Because their
  bootstrap is miscentered, \citet{CoS:07} must redefine
  $\hat{\beta}_t^{*}$ to achieve consistency.  In this paper, though,
  consistency arises naturally.
\end{rem}

\begin{rem}
  It may be unnecessary to assume that $\bar{f}(\beta_0)$ has positive
  definite asymptotic variance; if so, the bootstrap would work in the
  setup of \citet{ClM:05,ClM:01} and \citet{Mcc:07}.  That question is
  left to future research.
\end{rem}

\section{Monte Carlo Results}\label{sec:2}
I'll conduct two brief Monte Carlo experiments to demonstrate that
this paper's modified version of \citepos{ClW:07} statistic performs
similarly to their original test in the situations they
study.\footnote{All of these simulations were programmed in R
  \citep[version 2.14.0]{R} and use the \textsc{MASS} \citep[version
  info]{VeR:02}, xtable \citep[1.6-0]{Dah:09}, and dbframe
  \citep[version 0.2.1]{Cal:10b} packages.  For details on the
  programming, please see the supplemental appendix \citep{Cal:11f}.}
I'll use both of the \dgp s they consider as well as a modification to
study the performance of the statistics if there is instability.

The first \dgp\ has three different parametrizations; one to study the
tests' size, one to study power under stationarity, and one to study
power if there is a single break in the relationship between the
target and predictors.  The \dgp\ is:
\begin{align*}
  y_t &= 0.5 + \gamma^{*}_t z_{t-1} + e_t &
  \gamma^{*}_t &=
  \begin{cases}
    0    & \text{size simulations} \\
    0.35 & \text{power (stable)} \\
    0    & t \leq \tfrac{T}{2} \quad \text{power (break)} \\
    0.70 & t > \tfrac{T}{2} \quad \text{power (break)}
  \end{cases}\\\nonumber
  z_t &= 0.15 + 0.95 z_{t-1} + v_t &
  (e_t, v_t)' &\sim iid\ N\Bigg(\begin{pmatrix} 0 \\ 0
  \end{pmatrix}
   , \begin{pmatrix} 18 & -
    0.5 \\ -0.5 & 0.025 \end{pmatrix}\Bigg).
\end{align*}
Both models are estimated by \ols. The benchmark model regresses $y_t$
on a constant, and the alternative regresses $y_t$ on a constant and
$z_{t-1}$.  We use both \poscw\ original statistic and the new
statistic to test the null that the benchmark model's innovation is an
\mds.\footnote{\citet{ClW:07} report the performance of the tests
  proposed by \citet{CCS:01} and \citet{ClM:05} as well, and of tests
  based on the naive Gaussian statistic.}  \citet{ClW:06,ClW:07} only
look at the stable case.

\begin{table}[tb]
  \centering
  \input{tex/mc1}
  \caption{Size and power of the \oos\ tests under \eqref{eq:dgp1} at
    \testsize\% confidence.  These percentages are calculated from \totalsims\
    samples.  Pr[\textsc{cw}] shows the fraction of simulations for which Clark
    and West's (2007) statistic rejects; Pr[new] shows the fraction of
    simulations for which this paper's test rejects; and Pr[disagree]
    gives the fraction of simulations in which this paper's test and
    Clark and West's (2007) give different conclusions.}
\label{tab:mc1}
\end{table}

The second \dgp\ is
\begin{align*}
  y_{t} &= 2.237 + 0.261 y_{t-1} + \gamma^{*}_{1} z_{t-1} + \gamma_{2}^{*}
  z_{t-2} + \gamma_{3}^{*} z_{t-3} + \gamma_{4}^{*} z_{t-4} + e_{t} \\
  z_{t} &= 0.804 z_{t-1} - 0.221 z_{t-2} + 0.226 z_{t-3} - 0.205
  z_{t-4} + v_{t} \nonumber \\
  \binom{e_{t}}{v_{t}} &\sim N\Bigg(
  \begin{pmatrix}
    0 \\ 0
  \end{pmatrix},
  \begin{pmatrix}
    10.505 & 1.036 \\ 1.036 & 0.366
  \end{pmatrix}
  \Bigg) \nonumber\\\nonumber
  \gamma^{*} &=
  \begin{cases}
    0 & \text{size simulations}\\
    (3.363, -0.633, -0.377, -0.529)' & \text{power simulations}.
  \end{cases}
\end{align*}
The benchmark model for $y_{t}$ is an AR(1) and the alternative model
includes all four lags of $z_{t}$.  For this simulation, $R$ is 80 or
120 and $P$ is 40, 80, 120, or 160.  \citet{ClW:07} argue that the
first \dgp\ mimics an asset pricing application and the second mimics
\gdp\ growth forecasting using the Federal Reserve Bank of Chicago's
National Activity Index.

\begin{table}[tb]
  \centering
  \input{tex/mc2}
  \caption{Size and power of the \oos\ tests under \eqref{eq:dgp2} at
    \testsize\% confidence.  These percentages are calculated from \totalsims\
    samples.  Pr[\textsc{cw}] shows the fraction of simulations for which Clark
    and West's (2007) statistic rejects; Pr[new] shows the fraction of
    simulations for which this paper's test rejects; Pr[disagree] gives
    the fraction of simulations in which this paper's test and Clark and
    West's (2007) give different conclusions.}
\label{tab:mc2}
\end{table}

Table~\ref{tab:mc1} presents the simulation results for~\textsc{dgp}~1
and Table~\ref{tab:mc2} for~\textsc{dgp}~2.  For all of the stable
parameter values, the proposed new statistic has similar rejection
probability to \citepos{ClW:07}.  Clark and West's test is slightly
more undersized than the new test, but has a little higher power under
the alternative.  Moreover, the statistics give different results in
less than 10\% of the simulations for most parametrizations of the
\dgp s.  In general, the statistics perform similarly well.

For the simulations with a single break, the new statistic has about
twice the power of \poscw\ original test.  For most parametrizations
of \dgp\ 1, the new test rejects over 90\% of the time, while Clark
and West's test rejects about 40\% of the time.  So mixing window
strategies can give a substantial power advantage when testing for
time-varying predictability, and performs similarly to the original
test when testing for stable outperformance.

\section{Empirical Illustration}\label{sec:3}

This section demonstrates the use of our new statistics by revisiting
\citepos{GoW:08} study of excess stock returns.  Goyal and Welch argue
that many variables thought to predict excess returns (measured as the
difference between the yearly log return of the S\&P 500 index and the
T-bill interest rate) on the basis of in-sample evidence fail to do so
out-of-sample.  To show this, Goyal and Welch look at the forecasting
performance of models using a lag of the variable of interest, and
show that these models do not significantly outperform the excess
return's recursive sample mean.

Here, I conduct the same analysis, but using this paper's \mds\ test.
The benchmark model is the excess return's sample mean (as in the
original) and the alternative models are of the form
\[\text{excess return}_{t} = \alpha_{0} + \alpha_{1}\ 
\text{predictor}_{t-1} + \varepsilon_{t},\] where $\alpha_{0}$ and
$\alpha_{1}$ are estimated by \ols\ using a \windowlength-year window.
The predictors used are listed in the ``predictor'' column of
Table~\ref{tab:em1} \citep[see][for a detailed description of the
variables]{GoW:08}.  We also consider \citepos{CaT:08} proposed
correction to the models, that the forecasts be bounded below by zero
since negative forecasts are incredible, as well as two simple
combination forecasts, the mean and the median (over both the original
and the non-negative forecasts).  The data set is annual data
beginning in 1927 and ending in 2009, and the rolling window uses
\windowlength\ observations.\footnote{This statistical analysis was
  conducted in R \citep{R} using the xtable
  \citep[version~1.6-0]{Dah:09}, and dbframe \citep[version
  0.2.5]{Cal:10b} packages; please see the supplemental appendices for
  details on the programming \citep{Cal:11f}.}

Table~\ref{tab:em1} presents the results for each model.  The column
``value'' gives the value of the test statistic for each model, while
the ``naive'' and ``corrected'' columns indicate whether the statistic
is greater than the standard size-\bootsize\% critical value (1.28)
and the critical value estimated by the procedure of
Theorem~\ref{res:2} (\empiricalcriticalvalue).\footnote{The bootstrap
  uses \nboot\ replications with i.i.d. sampling, as proposed in
  Part~(\ref{it:1}) of Theorem~\ref{res:2}.}  Three predictors are
significant at the naive critical values for both the original and
bounded forecasts: the dividend yield, long term interest rate, and
book to market ratio.  But none are significant after accounting for
data snooping, which highlights the importance of these methods.  The
median forecast is significant using conventional critical values as
well, but not the corrected values.

\begin{table}[tb!]
  \centering
  \empiricaltable
\caption{Results from \oos\ comparison of equity premium prediction
  models; the benchmark is the recursive sample mean of the equity
  premium and each alternative model is a constant and single lag of
  the variable listed in the ``predictor'' column.  The dataset begins
  in 1927 and ends in 2009 and is annual data. The ``value'' column
  lists the value of this paper's \oos\ statistic, the ``naive''
  column indicates whether the statistic is significant at standard
  critical values, and the ``corrected'' column indicates significance
  using the critical values proposed in Theorem~\ref{res:2} that
  account for the number of models.  See Section~\ref{sec:3} for details.}
\label{tab:em1}
\end{table}


\section{Conclusion}\label{sec:4}
This paper presents an \oos\ test statistic similar to \poscw\ that is
asymptotically normal when comparing nested or non-nested models.
Normality is achieved by estimating the alternative model using a
fixed-length rolling window---as do Clark and West---but estimating
the benchmark model with a recursive window.  Simulations indicate
that the new statistic behaves similarly to Clark and West's original
test when the \dgp\ is stable, but can have much higher power when the
predictability varies over time, suggesting that the new statistic is
a suitable replacement in applied research.  The paper also presents a
method for comparing the benchmark model to several alternative models
simultaneously and improves block bootstrap procedures of \oos\
statistics.

\appendix
\section{Supporting Results}
This Appendix restates \citepos{Mcc:00} results, which themselves
weaken \citepos{Wes:96} assumptions, but under the dependence
conditions of Theorem~\ref{res:1}.  It also proves some of the Lemmas
required for that result and the results in the main paper.

\begin{lema}\label{res:a2}
  Suppose $a \in [0,\frac12)$ and the conditions of Theorem~\ref{res:3}
  hold.
  \begin{enumerate}
  \item $P^a \sup_t | H_{t} | \to^p 0$ and $P^a \sup_t | H_{t}^{*} |
    \to^{p^{*}} 0$.
  \item $P^a \sup_t | \hat{\beta}_{t} - \beta_{0} | \to^{p} 0$ and
    $P^a \sup_t | \hat{\beta}^{*}_{t} - \hat{\beta}_{T+1} |
    \to^{p^{*}} 0$.
  \end{enumerate}
\end{lema}

\begin{proof}[Proof of Lemma~\ref{res:a2}] \quad
  \begin{enumerate}
  \item The process $\tfrac{1}{\sqrt{T}} h_{s}$ satisfies \citepos[Theorem
    3.1]{JoD:00b} functional \clt.  So
    \begin{equation}
      P^a \sup_t \Big| \tfrac1t \sum_{s=1}^t h_{s} \Big| =
      P^a \sup_{\gamma \in [0,1]} \Big| \tfrac{1}{\lfloor \gamma
        T\rfloor} \sum_{s=1}^{\lfloor \gamma T \rfloor} h_{s} \Big| \to^{p} 0
    \end{equation}
    with the convergence following from the continuous mapping
    theorem.  \citepos{Cal:11d} Theorem~1 ensures the same argument
    holds for $\tfrac{1}{\sqrt{T}} h_s^{*}$.
  \item We have
    \begin{multline}
      P^a \sup_{t \in S_T} | \hat{\beta}_t - \beta_0 | = P^a \sup_{t
        \in S_T} |\hat{B}_{t} H_{t}| \\ \leq \sup_{t,u \in S_T} \Big|
      [ \hat{B}_u - B] \tfrac{P^a}{t} \sum_{s=1}^t h_{s} \Big| + \sup_{t\in S_T} \Big|
      B \tfrac{P^a}{t} \sum_{s=1}^t h_{s} \Big|
    \end{multline}
    and both terms converge to zero in (conditional) probability by
    the previous argument and by assumption.  The same argument holds
    for $\hat{\beta}_t^{*} - \hat{\beta}_{T+1}$ as well.
  \end{enumerate}
\end{proof}

\begin{lema}\label{res:a3}
  Suppose the conditions of Theorem~\ref{res:3} hold; let $\psi_{t} =
  (f_{t}' - \E f_{t}', a_t h_{t}')'$, $\psi_t^{*} =
  (f_t^{*}(\hat{\beta}_{T+1})' - \bar{f}(\hat{\beta}_{T+1})', a_t
  h_t^{*\prime})'$, and $a_t = \sum_{s=\max(R,t)}^T \tfrac{1}{s}$.  Then
  \begin{equation}\label{eq:1}
    \pr\Big[\sup_x \Big| \pr^{*}\Big[ \tfrac{1}{\sqrt{P}} \sum_{t=R+1}^T \psi_{t}^{*}
    \leq x \Big] - \pr\Big[ \tfrac{1}{\sqrt{P}} \sum_{t=R+1}^T \psi_{t}
    \leq x \Big] \Big| > \epsilon \Big] \to 0
  \end{equation}
  for all positive $\epsilon$.
\end{lema}

\begin{proof}[Proof of Lemma~\ref{res:a3}]
  Note that $\psi_t$ satisfies a \clt, \citep[Theorem~2]{Jon:97}, and
  so it suffices to prove that the bootstrap average obeys a \clt\ as
  well.

  Suppose that $\psi_t^{**}$ is generated by the stationary bootstrap but
  with exactly $\lfloor p P \rfloor$ full blocks of length
  $M_1,\dots,M_{\lfloor p P \rfloor}$ (so that the number of
  observations $P^{**}$ is random).  As in \citet{Cal:11d}, $\sqrt{P}
  \bar{\psi}^{*}$ and $\sqrt{P^{**}} \bar{\psi}^{**}$ converge in
  distribution to the same limit; moreover, $P^{**} \bar{\psi}^{**}$ is a
  sum of $\lfloor p P \rfloor$ independent blocks that obey a central
  limit theorem conditional on $\mathcal{M} = (M_1,\dots,M_{\lfloor p
    P \rfloor}$), and the result follows if $P^{**}
  \E^{**}(\bar{\psi}^{**} \bar{\psi}^{**\prime} \mid \mathcal{M}) \to^p
  \Sigma$ where $\Sigma = P \E(\bar{\psi} \bar{\psi}')$.

  For $\tau = 1,\dots,P^{**}$, let $\kappa$ denote the block
  containing $\tau$, so $\sum_{i=1}^{\kappa-1} M_i < \tau \leq
  \sum_{i=1}^{\kappa} M_i$, and let $K_{\tau,i} = \sum_{j=\kappa+1}^i
  M_{(j \mod \lfloor p P \rfloor) + 1}$, $K_{\tau,0} = 0$.  Then we have
  \begin{multline}
    P^{**} \E^{**}(\bar{\psi}^{**} \bar{\psi}^{**\prime} \mid \mathcal{M})
    = \tfrac{1}{P^{**}} \sum_{i=1}^{\lfloor p P \rfloor} 
    \sum_{s,t=K_{\tau,i-1}}^{K_{\tau,i}} \hat{\psi}_s \hat{\psi}_t' 
    \\ = \tfrac{1}{P^{**}} \sum_{i=1}^{\lfloor p P \rfloor}
    \sum_{s,t=K_{\tau,i-1}}^{K_{\tau,i}} \big[\psi_s \psi_t' + \psi_s(\hat{\psi}_t
    - \psi_{t})' + (\hat{\psi}_s - \psi_{s}) \psi_{t}' + (\hat{\psi}_s -
    \psi_{s})(\hat{\psi}_t - \psi_{t}) \big],
  \end{multline}
  with the first equality from \citet{Cal:11d} and $\hat{\psi}_s =
  (f_t(\hat{\beta}_{T+1})' - \bar f(\hat{\beta}_{T+1})', h_t')'$.
  Now, $\frac{1}{P^{**}} \sum_i \sum_{s,t} \psi_s \psi_t \to^p \var(\sqrt{P} \bar{\psi})$
  \citep[Lemma~5]{Cal:11d}, so it suffices to show that the remaining
  terms vanish, which is equivalent to showing
  \begin{equation}\label{eq:3}
    \tfrac{1}{P^{**}} \sum_{i=1}^{\lfloor p P \rfloor}\sum_{s,t =
      K_{\tau,i-1}}^{K_{\tau,i}} (f_s(\hat{\beta}_{T+1}) -
    f_s(\beta_0)) (f_t(\hat{\beta}_{T+1}) - f_t(\beta_0))
    \to^p 0
  \end{equation}
  and
  \begin{equation}\label{eq:2}
    (\bar{f}(\hat{\beta}_{T+1}) - \E
    \bar{f}(\beta_0)) (\bar{f}(\hat{\beta}_{T+1}) - \E
    \bar{f}(\beta_0))' \to^p 0.
  \end{equation}
  Proving~\eqref{eq:3} uses the same argument as~\citet[Lemma
  A.3]{Mcc:00} and~\eqref{eq:2} follows a streamlined version of the
  argument of~\ref{res:a5}, completing the proof.  The proofs for the
  moving and circular block bootstraps are the same.
\end{proof}

\begin{lema}\label{res:a5}
  If the conditions of Theorem~\ref{res:3} hold\footnote{The
    assumptions governing $\hat{\beta}_t^{*}$ are unnecessary.} then
  \begin{equation}
    \tfrac{1}{\sqrt{P}} \sum_{t=R+1}^T
    (f_{t}(\hat{\beta}_{t}) - \E f_{t}(\beta_{0})) \to^d N(0, \Omega),
  \end{equation}
  with $\Omega$ given in \citet[Theorem 2.3.1]{Mcc:00}.
\end{lema}
\begin{proof}[Proof of Lemma~\ref{res:a5}]
  The proof follows exactly as in \citet[Theorem 2.3.1]{Mcc:00}.
\end{proof}

\section{Proofs of Main Theoretical Results}\label{sec:B}

\begin{proof}[Proof of Theorem \ref{res:1}]
  Replace $R$ with $\log(T)$ and $P$ with $T - \log(T)$ in the
  statistic; this substitution does not affect its asymptotic
  distribution; the theorem is now an immediate consequence of
  Lemma~\ref{res:a5}.  Note that \[f_t(\beta_0)= 2 (y_{t+1} -
  x_t'\beta_0)(\hat{y}_{1,t+1} - x_t'\beta_0) \quad \text{a.s.},\] as
  in \citet{ClW:07}, which is an \mds, so we do not need to use a
  \hac\ estimator of the variance under the null.
\end{proof}

\begin{proof}[Proof of Theorem \ref{res:2}]
  Replace $R$ and $P$ as in the proof of Theorem~\ref{res:1}.
  Theorem~\ref{res:3} of this paper, Theorem~3.1 and~4.1 of
  \citet{RoW:05}, and Theorem~1 of \citet{Cal:11e} complete the proof.
\end{proof}

\begin{proof}[Proof of Theorem~\ref{res:3}] Expand $\E^{*}
  f_t^{*}(\hat{\beta}_t^{*})$ around $\hat{\beta}_{T+1}$ to get
  \begin{equation}
    \sqrt{P} (\bar{f}^{*} - \bar{f}(\hat{\beta}_{T+1})) =
    \tfrac{1}{\sqrt{P}} \sum_{t=R+1}^T
    \big[f_t^{*}(\hat{\beta}_{T+1}) - \bar{f}(\hat{\beta}_{T+1}) +
    F^{*} B^{*} a_t h_t^{*} \big] + o_{p^{*}},
  \end{equation}
  with $a_t = \sum_{s=\max\{t,R\}}^T \tfrac1s$.  The proof is the same
  as in \citet[Theorem 2.3.1]{Mcc:00}.  Note that $F^{*} = \hat{F} +
  o_{p}(1) = F + o_p(1)$ and $B^{*} = B + o_{p}(1)$.  The result then
  follows from Lemma~\ref{res:a3}.
\end{proof}

\begin{lem}[Formalization of Remark~\ref{rem:01}]
  Suppose that the conditions of Theorem~\ref{res:2} Part~\ref{it:3}
  hold but $f_i = (f_{i1},\dots,f_{iq})$ and the asymptotic variance
  of $(\bar{f}_{1k}(\beta_k),\dots,\bar{f}_{mk}(\beta_k))$ is
  uniformly positive definite for each $k$.  Then the procedure
  described in Remark~\ref{rem:01} achieves \textsl{\sfwe}.
\end{lem}

The proof is similar to that of Theorem~\ref{res:2}. Note that we
allow $\sqrt{P}(\bar{f}_{i1}(\beta_1),\dots,\bar{f}_{iq}(\beta_q))$ to
converge to a normal with singular variance-covariance matrix as long
as each element has positive variance.

\bibliography{texextra/AllRefs}
\end{document}

% LocalWords:  ClW JEL ISI Google GiW Mcc ClM CoS CCS StW IMA GiR WeM fh X'X hh
% LocalWords:  PaT AllRefs isi ima uc sv PeT GoW lm il GoK RoW Econometrica PoR
% LocalWords:  Finan StepM studentizing studentization Whi HuW RSW recentering
% LocalWords:  DiM LiS Kun McCracken lt filtrations GoJR JoD McCracken's Econom
% LocalWords:  Corradi unstudentized studentized fg gg GoJ gcalhoun HLN li PoW
% LocalWords:  Econometricians reestimate PPW resample miscentered AnG eq Helle
% LocalWords:  Bunzel Yu Hsu Pincheira HHK th AtO ik DoH Wolak's Wol stepdown
% LocalWords:  Hsu's iq mk Ames Amit Goyal rfs Ivo Welch Wes covariance MeR McW
% LocalWords:  familywise prespecified CoD Gia pointwise misspecified InK MeP
% LocalWords:  VeR xtable Dah dbframe oos parametrizations iid dgp return's CaT
% LocalWords:  outperformance Hmisc Har
