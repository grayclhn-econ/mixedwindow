\documentclass[12pt,fleqn]{article}
\input{tex/setup}
\input{tex/mcDef}
\input{tex/ap}

% These commands are generated when the Monte Carlo and applied
% sections are run; I'm giving them definitions now so that LaTeX will
% compile the document even if that code hasn't been run yet.
\providecommand\bootsize{[missing]}
\providecommand\empiricalcriticalvalue{[missing]}
\providecommand\nboot{[missing]}
\providecommand\testsize{[missing]}
\providecommand\totalsims{[missing]}
\providecommand\windowlength{[missing]}
\providecommand\empiricaltable{[missing]}

\author{Gray Calhoun\thanks{ Economics Department; Iowa State
    University; Ames, IA 50011.  Telephone: (515) 294-6271.  Email:
    \guillemotleft \protect\url{gcalhoun@iastate.edu}\guillemotright,
    web: \guillemotleft www.econ.iastate.edu/\textasciitilde
    gcalhoun\guillemotright.
    I'd like to
    thank Helle Bunzel, Todd Clark, Graham Elliott, Yu-Chin Hsu,
    Michael McCracken, Pablo Pincheira, Allan Timmermann, Stephane
    Meng-Feng Yen and participants at the 2011 Midwest Econometrics
    Group meeting and the 2013 NBER-NSF Time Series conference
    for helpful comments and discussions.  I'd also like to thank Amit
    Goyal for providing computer code and data for his 2008
    RFS paper with Ivo Welch \citep{GoW:08}.}\\%
  Iowa State University}

\title{An asymptotically normal out-of-sample
  test of equal predictive accuracy for nested models} 

% \date{March 14, 2013}

\begin{document}
\maketitle

\begin{abstract} 
  \noindent This paper develops a modification of \citepos[\textit{J.
    Econom.}]{ClW:07} adjusted out-of-sample $t$-test. We propose
  using a recursive window to estimate the benchmark model but a
  fixed-length rolling window to estimate the alternative. The
  resulting statistic is asymptotically normal even when the models
  are nested.  Moreover, the alternative model can be estimated using
  common model selection methods, such as the \aic\ or \bic, without
  affecting the asymptotic distribution of this test statistic.  The
  paper also presents Monte Carlo evidence that this statistic has
  much higher power than existing out-of-sample statistics in a common
  use-case for these tests: when the DGP is subject to instability.
  This procedure is then used to analyze
  \citepos[\textit{Rev. Finan. Stud.}]{GoW:08} excess returns dataset
  and supports their finding that the equity premium is unpredictable
  out-of-sample.

\strut

\noindent Keywords: Forecast Evaluation, Martingale Difference
Sequence, Model Selection

\strut

\noindent JEL Classification Numbers: C22, C53

\end{abstract}

\newpage 

\section{Introduction} This paper proposes an out-of-sample (\oos)
test statistic that is asymptotically normal with mean zero even when
the models studied are nested.
\oos\ tests are commonly used in International Macroeconomics,
Macroeconomics, and Finance (see, for example, \citealt{MeR:83};
\citealt{StW:03}; and \citealt{GoW:08}) and there is a substantial
literature developing the theoretical properties of these statistics,
beginning primarily with \citet{DiM:95} and
\citet{Wes:96}.%
\footnote{Other papers in this literature include
  \citet{WeM:98}, \citet{Mcc:98,Mcc:00},
  \citet{ClM:01,ClM:05-2,ClM:05,ClM:11b,ClM:12,ClM:12b},
  \citet{CCS:01}, \citet{CoS:02,CoS:04,CoS:07}, \citet{Whi:00},
  \citet{InK:04,InK:06}, \citet{Han:05}, \citet{Ros:05},
  \citet{ClW:06,ClW:07}, \citet{Ana:07}, \citet{GiR:09,GiR:10},
  \citet{HuW:10}, \citet{HLN:11}, \cite{InR:11}, \cite{Pin:11},
  \cite{RoS:11,RoS:11b}, and \citet{Cal:11}, among others.  For recent
  reviews of this literature and additional references, see
  \citet{McW:02}, \citet{CoS:06}, \citet{Wes:06}, \citet{ClM:11c},
  \citet{CoD:11}, and \citet{Gia:11}} %
In a pair of papers,
\citet{ClW:06,ClW:07} develop an \oos\ test of the null hypothesis
that a small benchmark model is correctly specified.  Their test
compares the forecasting performance of a pair of nested models, and
the null hypothesis is that the innovations in the smaller model form
a Martingale Difference Sequence (\mds).  This test procedure is popular, and
one assumes that this is due in part to the statistic's convenience,
the statistic is approximately normal after adjusting for the
estimation error of the larger model.  Normality comes from a
fixed-length rolling window, as in \citet{GiW:06}, and the adjustment
centers the statistic appropriately.  This statistic is especially
convenient because other \oos\ tests for similar hypotheses
(\citealt{CCS:01}; \citealt{ClM:01,ClM:05}; \citealt{CoS:02,CoS:04};
and \citealt{Mcc:07}; among others) have a nonstandard limit
distribution and place restrictions on the models under consideration,
while other asymptotically normal statistics test a different null
hypothesis \citep{GiW:06} or place assumptions on the models and \dgp\
that are often violated in empirical work (\citealt{DiM:95};
\citealt{Wes:96}; \citealt{WeM:98};
\citealt{Mcc:00}).%
\footnote{\citet{DiM:95} assume that the models are
  not estimated. \citet{Wes:96}, \citet{WeM:98}, and \citet{Mcc:00}
  implicitly assume that the models do not converge to the same limit,
  which rules out nesting.} %

However, Clark and West's statistic is only ``approximately normal''
in an informal sense.  Clark and West present Monte Carlo evidence of
the statistic's distribution, but only prove that the statistic is
asymptotically normal with mean zero when the benchmark model is a
random walk \citep{ClW:06}. Estimating the parameters of the smaller
model invalidates their proof.

In this paper, I show that a modified version of their statistic is
asymptotically normal even when the smaller model is estimated.  To
achieve normality, the pseudotrue benchmark model must be estimated
consistently, but the larger alternative model must continue to be
estimated inconsistently so that the test statistic is not degenerate
when the models are nested. We can meet both needs by
using different window strategies for each model: the benchmark model
is estimated using a recursive window and the alternative with a
fixed-length rolling window.

Mixing window strategies is uncommon but needn't be. In most
applications, the null hypothesis imposes stability as well as equal
accuracy between the two models.  The benchmark model rarely allows
for breaks, parameter drift, or other forms of
instability,%
\footnote{Exceptions are \citepos{StW:07}
  IMA(1,1) and UC-SV models of inflation.} %
but the
researcher is typically concerned about instability.  Indeed, concern
about instability is often given as a reason for doing an \oos\
analysis, especially with a short rolling window.%
\footnote{This
  motivation is discussed by \citet{StW:03}, \citet{PeT:05,PeT:07},
  \cite{GiW:06}, \citet{GoW:08}, \citet{ClM:09c}, and
  \cite{GiR:09,GiR:10}, among others.} %
A researcher could impose
stability on both models by using a recursive window or relax
stability for both by using a rolling window; either approach should
not affect the test's size, but may affect power.  But the researcher
could instead impose stability on the benchmark and relax it for the
alternative by using a recursive window for the benchmark and a
rolling window for the alternative model.  This approach could have a
power advantage and is similar in spirit to using a Likelihood Ratio
Test instead of an LM or Wald test, which depend on just the
restricted or unrestricted model respectively.

This paper's statistic has a substantial advantage over existing \oos\
tests for nested models: the alternative can be essentially arbitrary
as long as high level moment conditions hold.  In particular,
researchers can use model selection techniques like the \aic\ or \bic\
to determine the number of lags to include, the particular exogenous
variables to include, etc.  Other methods that test a similar
hypothesis are unable to handle these models \citep[except][which does
not allow the benchmark to be estimated]{ClW:06}; \citet{GiW:06} are
able to handle such models for both the alternative and the benchmark
but, as mentioned earlier, they test a different aspect of forecasting
performance.

This paper focuses on nested models, as they have received the most
attention in the empirical and theoretical literature, but the
statistic can be used with non-nested models as well.  This generality
is useful, since \citepos{Wes:96} results do not apply to non-nested
models if they both encompass the true \dgp,%
\footnote{\citet{ClM:11b}
  call this scenario, ``overlapping models.''} %
which is allowable
under the null: in the limit, both models will converge to the \dgp\
and give identical forecasts.  Consequently, the naive \oos\ $t$-test
is invalid, even after correcting the standard error if necessary to
reflect parameter uncertainty.  \citet{ClM:11b} show that the fixed
window \oos\ $t$-test remains normal for these models but the
recursive and rolling windows (with the window size increasing to
$\infty$) do not, and provide a procedure for pointwise (but not
uniformly) valid tests for the recursive and rolling windows and
uniformly valid tests for the fixed window.  The test proposed in this
paper is uniformly valid and places fewer assumptions on the models
under study and the true \dgp.

The next section presents our new statistics and Section~\ref{sec:2} presents
simulations that compare our test to \poscw\ original
statistics.  Section~\ref{sec:3} demonstrates the use of our statistic
by reanalyzing \citepos{GoW:08} study of excess return
predictability and Section~\ref{sec:4} concludes. Proofs of
our results have been put in a separate Appendix along with
some minor supporting arguments \citep{Cal:14}.

\section{Theoretical results supporting the asympotically normal OOS statistic}
\label{sec:1}

This section presents the new \oos\ statistic; first we give an
informal motivation of the statistc, then present the paper's key
assumptions in section~\ref{sec:1a} and present our formal theoretical
results in section~\ref{sec:1b}.

Suppose for now that a researcher is interested in
predicting the target variable $y_{t+1}$ with a vector of regressors
$x_t$; also let $v_t$ be another random process that is believed to
potentially contain information about $y_{t+1}$ and suppose that
$(y_t, x_t, v_t)$ is stationary and weakly dependent.
In addition,
let $\btrue = (\E x_t x_t')^{-1} \E x_t y_{t+1}$ be the pseudotrue
coefficient for the regression of $y_{t+1}$ on $x_t$ and define
$\ep_{t+1} = y_{t+1} - x_t'\btrue$.  If this linear model is
correctly specified, then $\ep_{t+1}$ is an \mds\ with respect
to the information set
\begin{equation*}
\mathcal{F}_t \equiv \sigma((x_t, v_t, y_t), (x_{t-1}, v_{t-1},
y_{t-1}),\dots),
\end{equation*}
and we can see immediately that
\begin{equation}
  \label{eq:4}
  \oclt{t} \ep_{t+1} (v_t - x_t'\btrue)
\end{equation}
obeys an \mds\ \clt and is asymptotically normal as $P \to \infty$,%
\footnote{This claim assumes that the asymptotic variance of the
  sample average is uniformly positive, a requirement that we will
  address in Section~\ref{sec:1b}.} %
with $R$ an arbitrary starting value%
\footnote{It will be clear momentarily why the summation begins at
  $R+1$ instead of $1$.} %
and $P = T - R$.%
\footnote{Section~\ref{sec:1b} discusses conditions under which the
  \mds\ condition holds. We will also present results that allow
  $\ep_{t+1}$ to be serially correlated.} %
Straightforward algebra \citep{ClW:07} shows that
\begin{equation}
  \label{eq:5}
  \tfrac{1}{\sqrt{P}} \osum{t} \ep_{t+1} (v_t -
  x_t'\btrue) = \tfrac{1}{2 \sqrt{P}} \osum{t} \Big[(y_{t+1} -
  x_t\btrue)^2 - (y_{t+1} - v_t)^2 + (x_t'\btrue - v_t)^2 \Big].
\end{equation}

\citet{ClW:06,ClW:07} base their \oos\ statistics on the RHS of
Equation~\eqref{eq:5}, but use a second forecast of $y_{t+1}$ as
$v_t$. (Call it $\yh_{1,t+1}$.) They use a rolling window of length
$R$ to estimate $\yh_{t+1}$%
\footnote{Making $\yh_{t+1}$ a function of $y_t, x_{t-1}, z_{t-1}
\dots, y_{t-R+1}, x_{t-R}$ and $z_{t-R}$, where $z_t$ is another weakly
dependent random process} %
and $R$ is kept finite as $T \to \infty$ so that
$\yh_{t+1}$ inherits the weak dependence properties of the
variables used to estimate it. Using a finite window length $R$ prevents
the degeneracy that can arise when comparing nested models out-of-sample (see
\citealp{ClM:01}, and \citealp{Mcc:07}), so the conditional variance
of the OOS average remains positive and the average obeys a \clt.%
\footnote{This approach was first introduced by \citet{GiW:06}.} %

\citet{ClW:06,ClW:07} develop a test of whether $\ep_{t+1}$ is
an \mds. In the 2006 paper, Clark and West assume that the
coefficients on the benchmark model, $\btrue$, are zero under the null, making
$\ep_{t+1}$ observed directly. This restriction is relaxed in
the 2007 paper, where $\btrue$ is unknown and estimated with length-$R$
rolling window. Now the estimated linear model's prediction errors,
$\eph_{t+1}$, replace $\ep_{t+1}$ in the \oos\
test statistic. Unfortunately, $\eph_{t+1}$ is not an
\mds\ even when $\ep_{t+1}$ is, so the statistic is no longer
asymptotically mean-zero normal, even though this approximation
performs well in simulations. Since the window length is finite,
the estimators of $\beta_0$ do not converge to $\beta_0$.

This paper proposes using the same basic \oos\ statistic, 
but using a recursive window to estimate $\btrue$ and produce
$\eph_{t+1}$; i.e.
\begin{equation}
  \label{eq:8}
  \bh_t = \Big(\sum_{s=2}^{t} x_{t-1} x_{t-1}'\Big)^{-1}
  \sum_{s=2}^t x_{t-1} y_t.
\end{equation}
\citepos{Wes:96} Theorem 4.1 implies that
\begin{equation*}
  \oclt{t} \Big[(y_{t+1} -
  x_t\bh_t)^2 - (y_{t+1} - v_t)^2 + (x_t'\bh_t - v_t)^2 \Big]
\end{equation*}
is asymptotically normal with mean zero under Clark and West's MDS
null for fairly
arbitrary processes $v_t$, as long as $v_t$ is weakly dependent and
the \oos\ statistic has uniformly positive variance.  Just as in
\citet{ClW:06,ClW:07}, these conditions are ensured if $v_t$ is
another forecast of $y_{t+1}$ based on a fixed-length rolling window.

This overview has presented an especially simple version of the result
to make the intuition as clear as possible. The next section lists the
specific assumptions for a more general case.

\subsection{Theoretical assumptions}
\label{sec:1a}

Consider the following environment. There is a single linear
benchmark model of the target variable, $y_{t+1}$:
\begin{equation}\label{eq:1}
  y_{t+1} = x_t'\beta + \ep_{t+1}, \quad t = 1,\dots,T+1
\end{equation}
where $\beta$ is an unknown $k$-vector of parameters and $x_t$ is an
observed vector of predictors. The parameter $\beta$ is
estimated with OLS using a recursive window as described by
Equation~\eqref{eq:8}
and the period-$t$ forecast is given by
\begin{equation}\label{eq:3}
  \yh_{0,t+1} = x_t'\bh_t.
\end{equation}

We deviate slightly from the previous section's introduction by
allowing for multiple alternative models, as in \cite{HuW:10}. This
allowance is crucial if we want the statistic to be empirically
useful, since almost every empirical analysis considers several
alternative models at once.  Each of these alternative models is
denoted $\yh_{j,t+1}$, for $j = 1,\dots,J$, and is estiatmed with a
rolling window of length $R$.

These conditions are summarized in the first assumption.

\begin{asmp}\label{a1}%
  The benchmark forecast, $\yh_{0,t+1}$, is generated by
  Equation~\eqref{eq:3}, where $\bh_t$ is constructed with a recursive
  window and satisfies~\eqref{eq:8}. The alternative forecasts are
  estimated using a rolling window of length $R$, so $\yh_{j,t+1} =
  \psi_j(y_t,z_t,\dots,y_{t-R+1}, z_{t-R+1})$ where $\psi_j$ is a
  known function and $z_t$ is a sequence of predictors that may
  include $x_t$. The window length, $R$, remains finite as $T \to
  \infty$.
\end{asmp}

Assumption~\ref{a3} describes the DGP. The weak dependence and moment
conditions are standard. These assumptions are slightly weaker than
similar assumptions in \citet{Wes:96} and \citet{Mcc:00}, but only
because we make use of more recent developments in limit theory, in
particular the CLT for Near-Epoch Dependent (NED) processes proven by
\cite{Jon:97}.

\begin{asmp}\label{a3}%
  The series $y_t$, $x_t$, and $z_t$ are NED of size $-1/2$ on either a
  strong mixing process of size $-\frac{r}{r-2}$ for $r>2$ or a uniform
  mixing process of size $-\frac{r}{2r-2}$ for $r \geq 2$. Moreover,
  $y_t$ and $\yh_{j,t+1}$, $j = 1,\dots,J$, have uniformly bounded $2 r$
  moments.
\end{asmp}

The requirement that the alternative forecasts satisfy a moment
condition, rather than the underlying predictors $z_t$, is somewhat
unappealing but necessary. The functions $\psi_j$ that generate these
forecasts is essentially unrestricted, so even well-behaved predictors
could produce arbitrarily badly-behaved forecasts. For example, if
\begin{equation*}
  z_t \sim \iid~\bernoulli(1/2),
\end{equation*}
setting $\psi_1(y_t, z_t) = 1/z_t$ would prevent a CLT from holding
since the forecast equals positive infinity with probability $1/2$. It
is easy to construct less obvious examples of problematic functions as
well. Assumption~\ref{a3} implicitly rules out these functional forms
by imposing moment conditions on the alternative models' forecasts.

Finally, we define some notation for the \oos\ statistic. The
adjusted OOS loss for each alternative model and a hypothetical value
of $\beta$ is denoted by
\begin{equation}
  f_{jt}(\beta) = (y_{t+1} - x_t'\beta)^2
  - (y_{t+1} - \yh_{j,t+1})^2 + (x_t'\beta - \yh_{j,t+1})^2
\end{equation}
and $f_t(\beta)$ denotes the vector $(f_{1t}(\beta),\dots,f_{Jt}(\beta))$.
Also define
\begin{align*}
  \fh_t &= f_t(\bh),
  &\fb(\beta) &= \oavg{t} f_t(\beta),
  &\text{and}&
  &\fb &= \tfrac1P \sum_{t=R+1}^{T} \fh_t
\end{align*}
with $P = T - R$. Also define $\beta_0$ to be the pseudotrue value of
$\beta$ that minimizes the MSE of the benchmark model,
\begin{equation*}
  \btrue = \plim \Big( \sum_{t=1}^T x_t x_t' \Big)^{-1} \sum_{t=1}^T x_t y_{t+1},
\end{equation*}
and let $\Sigma$ be the asymptotic variance of $\fb$, $\Sigma
= \lim_{T \to \infty} \var(\sqrt{P} \fb)$.
The next assumption ensures that $\Sigma$ is positive definite.
\begin{asmp}\label{a4}%
  The asymptotic variance of $\fb$, $\Sigma$, is positive definite.
\end{asmp}

This assumption is much less restrictive than in \cite{Wes:96}.  As in
\cite{GiW:06} and \citet{ClW:06,ClW:07}, the assumption only serves to
rule out pathological cases---for example, letting both the benchmark
and the alternative models be perfectly correlated white noise. In
\citet{Wes:96}, this assumption is a restriction on the \dgp\ as well
as the forecasting models, but in this paper it is a restriction only
on the models.

\subsection{Theoretical results}
\label{sec:1b}

\begin{thm}\label{res:1}\input{mixedwindow_thm1}\end{thm}

The following remarks are relevant to Theorem~\ref{res:1}:

\begin{rem}
  Forecasters are usually interested in the one-sided alternative that
  $\E f_t > 0$; i.e. that the alternative model is expected
  to forecast better than the benchmark.
\end{rem}

\begin{rem}
  These results are presented for one-period-ahead forecasting for
  simplicity.  They can be extended to forecasting at a longer horizon
  by appropriately modifying the variance-covariance matrix to account
  for the correlation structure of the forecast errors. (i.e. for
  $\tau$-step-ahead forecasts the errors will be an \ma($\tau-1$) process).
\end{rem}

Define $\X' = [x_1,\dots,x_T]$

\begin{align*}
  \Fh &= \Big\{\tfrac{2}{P}\sum_{s=R}^T x_s (x_s'\beta - \yh_{1,s+1}) \Big\}' &
  \Bh &= \big(\tfrac1T \X'\X \big)^{-1}
\end{align*}

Define the variables
$g_t(\beta) = \Fh \Bh x_t(y_{t+1} - x_t'\beta)$,
$\gh_t = g_t(\bh_t)$, and $\gb = \oavg{t} \gh_t$.

\newcommand{\K}[1]{K(\tfrac{#1}{w})}

Define the general covariance estimator:
\begin{align*}
  \Sigmah_1 &= \Sh_{21} + \Sh_{22} + \Sh_{22}' + 2 \, \Sh_{23}, &
  \Sh_{11} &= \oavg{s,t} (\fh_t - \fb) (\fh_t - \fb)' \K{t-s}, \\
  \Sh_{12} &= \oavg{s,t} (\fh_t - \fb)(\gh_t - \gb)' \K{t-s}, &
  \Sh_{13} &= \oavg{s,t} (\gh_t - \gb)(\gh_t - \gb)'  \K{t-s}.
\end{align*}

Define the MDS covariance estimator:
\begin{align*}
  \Sigmah_2 &= \Sh_{21} + \Sh_{22} + \Sh_{22}' + 2 \, \Sh_{23}, &
  \Sh_{21} &= \oavg{t} (\fh_t - \fb) (\fh_t - \fb)', \\
  \Sh_{22} &= \oavg{t} (\fh_t - \fb)(\gh_t - \gb)', &
  \Sh_{23} &= \oavg{t} (\gh_t - \gb)(\gh_t - \gb)'.
\end{align*}

\begin{lem}\label{lem:2}\input{mixedwindow_lem2}\end{lem}

\begin{rem}
  The statistic we present tests the null hypothesis that the forecast
  errors from the population version of the benchmark model are a
  martingale difference sequence.  This hypothesis may not be
  appropriate, depending on the loss function or utility function of
  interest.  If one wants to test the less restrictive null hypothesis that
  $y_{t} - \yh_{0t}$ is uncorrelated with $\yh_{1t}$ but not
  necessarily an \mds, one can replace $\Sh_{21}$, $\Sh_{22}$
  and $\Sh_{23}$ with their \hac\ counterparts.
  Our statistic can also be modified to test implications of
  optimal forecasts under other loss functions
  \citep[see][]{PaT:07,PaT:07b}; the statistic should be expressed as
  a forecast encompassing test using the models' generalized forecast
  errors.%
\footnote{See \citet{HLN:98} and \citet[Section~4]{ClW:07}.} %
\end{rem}

\section{Monte Carlo Results}\label{sec:2}
This section presents Monte Carlo experiments demonstrating that
this paper's modified version of \citepos{ClW:07} statistic performs
similarly to their original test in the situations they study, but can
have substantially higher power when the \dgp\ has a structural
break.%
\footnote{All of these simulations were programmed in R
  \citep[version 2.14.0]{R} and use the MASS
  \citep[7.3-22]{VeR:02} package.} %

The \dgp\ has three different parametrizations: one to study the
tests' size, one to study power under stationarity, and one to study
power if there is a single break in the relationship between the
target and predictors.  The \dgp\ is:
\begin{align*}
  y_t &= \gamma_{1t} + \gamma_{2t} z_{t-1} + e_t &
  \gamma_t &=
  \begin{cases}
    (0.5, 0)    & \text{size simulations} \\
    (0.5, 0.35) & \text{power (stable)} \\
    (-0.5, 0)    & t \leq \tfrac{T}{2} \quad \text{power (break)} \\
    (1, 0.35) & t > \tfrac{T}{2} \quad \text{power (break)}
  \end{cases}\\\nonumber
  z_t &= 0.15 + 0.95 z_{t-1} + v_t &
  (e_t, v_t)' &\sim iid\ N\Bigg(\begin{pmatrix} 0 \\ 0
  \end{pmatrix}
   , \begin{pmatrix} 18 & -
    0.5 \\ -0.5 & 0.025 \end{pmatrix}\Bigg)
  \\ R &= 120, 240 & P &= 120, 240, 360, 720.
\end{align*}
Both models are estimated by \ols. The benchmark model regresses $y_t$
on a constant, and the alternative regresses $y_t$ on a constant and
$z_{t-1}$.  \citet{ClW:07} argue that this \dgp\ mimics an asset
pricing application similar to \citepos{GoW:08} which we study in
Section~\ref{sec:3}.

For comparison, we study this paper's new statistic as well as \poscw\
rolling-window and recursive-window test statistics.  Clark and West
only prove that their rolling-window statistic is asymptotically
normal, and only then if the benchmark model is not estimated, but
their recursive-window statistic is popular in practice and in
simulations tends to perform similarly to their rolling window test.
We use all three of these statistics to test the null that the
benchmark model's innovation is an \mds.%
\footnote{\citet{ClW:07}
  report the performance of the tests proposed by \citet{CCS:01} and
  \citet{ClM:05} as well, and of tests based on the naive Gaussian
  statistic.} %

\begin{table}[tb]
  \centering
  \input{tex/mc1}
  \caption{Size and power of the \oos\ tests in the simulations 
    described by Section~\ref{sec:2}, at
    \testsize\% confidence.  These percentages are calculated from \totalsims\
    samples.  Pr[CW roll.] shows the fraction of simulations for
    which Clark and West's (2007) rolling-window statistic rejects; 
    Pr[CW rec.] shows the fraction of simulations for which
    their recursive-window statistic rejects; and Pr[new] shows the fraction of
    simulations for which this paper's test rejects.}
\label{tab:mc1}
\end{table}

Table~\ref{tab:mc1} presents the simulation results.  For all of the
stable parameter values, the proposed new statistic has similar
rejection probability to \citepos{ClW:07}.  Both of Clark and West's
tests are generally slightly undersized relative to our new test,
which is itself slightly undersized: when $R$ is 120 and $P$ is 360
our test statistic has size 7.6\% and Clark and West's rolling and
recursive window tests have size 7.5\% and 6.2\% respectively, at a
nominal size of 10\%.  For the stable alternative, our new statistic
typically has slightly higher power than Clark and West's rolling
window and lower power than their recursive window.  For example, when
$R$ is 120 and $P$ is 720, the rolling-window test rejects at 66.8\%,
our statistic at 73.0\%, and the recrusive window statistic at 82.3\%,
again for a nominal size of 10\%.  In general, the statistics perform
similarly under stability.

For the simulations with a single break, the new statistic has
considerably higher power than \poscw\ original tests across all of
the choices of $R$ and $P$; the rejection probability is more than
twice as large for most parametrizations.  When $R$ is 120 and $P$ is
360 with a nominal size of 10\%, for example, the new statistic
rejects at 96.4\% while the rolling and recursive window statistics
reject at 35.5\% and 32.9\% respectively.  Results for other choices
of nominal size and sample split give similar results.  So mixing
window strategies can give a large power advantage when testing for
time-varying predictability, and performs similarly to the original
test when testing for stable outperformance.

\section{Empirical Illustration}\label{sec:3}

This section demonstrates the use of our new statistic by revisiting
\citepos{GoW:08} study of excess stock returns.  Goyal and Welch argue
that many variables thought to predict excess returns (measured as the
difference between the yearly log return of the S\&P 500 index and the
T-bill interest rate) on the basis of in-sample evidence fail to do so
out-of-sample.  To show this, Goyal and Welch look at the forecasting
performance of models using a lag of the variable of interest, and
show that these models do not significantly outperform the excess
return's recursive sample mean.

Here, I conduct the same analysis, but using this paper's \mds\ test.
The benchmark model is the excess return's sample mean (as in the
original) and the alternative models are of the form
\begin{equation*}
  \mathit{excess~return}_{t} = \alpha_{0} + \alpha_{1}\
  \mathit{predictor}_{t-1} + \ep_{t},
\end{equation*}
where $\alpha_{0}$ and
$\alpha_{1}$ are estimated by \ols\ using a \windowlength-year window.
The predictors used are listed in the ``predictor'' column of
Table~\ref{tab:em1} \citep[see][for a detailed description of the
variables]{GoW:08}.  We also consider \citepos{CaT:08} proposed
correction to the models, that the forecasts be bounded below by zero
since negative forecasts are incredible, as well as two simple
combination forecasts, the mean and the median (over both the original
and the non-negative forecasts).  The data set is annual data
beginning in 1927 and ending in 2009, and the rolling window uses
\windowlength\ observations.%
\footnote{This statistical analysis was conducted in R \citep{R} and
  uses the MASS \citep[7.3-22]{VeR:02} package.} %

\begin{table}[tb!]
  \centering
  \empiricaltable
\caption{Results from \oos\ comparison of equity premium prediction
  models; the benchmark is the recursive sample mean of the equity
  premium and each alternative model is a constant and single lag of
  the variable listed in the ``predictor'' column.  The dataset begins
  in 1927 and ends in 2009 and is annual data. The ``value'' column
  lists the value of this paper's \oos\ statistic, the ``naive''
  column indicates whether the statistic is significant at standard
  critical values, and the ``corrected'' column indicates significance
  using critical values that
  account for the number of models.  See Section~\ref{sec:3} for details.}
\label{tab:em1}
\end{table}

Table~\ref{tab:em1} presents the results for each model.  The column
``value'' gives the value of the test statistic for each model, while
the ``naive'' indicates whether the statistic is greater than the
standard \bootsize\% critical value (\naivecriticalvalue) Three
predictors are
significant at the naive critical values for both the original and
bounded forecasts: the dividend yield, long term interest rate, and
book to market ratio.

However, we know that this is an extremely optimistic assessment of
the models' performance. We are conducting \nmod\ simultaneous
hypothesis tests, so it is likely that some will reject by chance. A
full treatment of this issue is beyond the scope of this paper,
however, it is straightforward to use Theorem~\ref{res:1} and
Lemma~\ref{lem:2} to derive an appropriate critical value as
in~\citet{Whi:00}. Since $\sqrt{P} \fb \to^d N(0, \Sigma)$ under
the MDS null hypothesis, the continuous mapping theorem implies that
$\max_i \sqrt{P} \fb_i/\sh_i \to^d \max_i W_i$, where $Z_i
\sim N(0, D^{-1/2} \Sigma D^{-1/2})$ and $D = \diag(\sigma_1, \dots,
\sigma_j)$. We can simulate from the $N(0, \hat D^{-1/2} \Sh
\hat D^{-1/2})$ distribution to generate a critical value for the
\emph{largest} individual test statistic under the null ---
\empiricalcriticalvalue, based on \empiricaldraws\ simulations. Using
this critical value, none of the predictors are siginificant at
\bootsize\%.%
\footnote{\citet{Han:05} makes the point that multiple one-sided
  comparisons can have poor power if irrelevant predictors are
  included in these tests and proposes a threshold for discarding very
  poor forecasts. His threshold is well below our worst performing
  model, so this issue is not a concern here. Moreover, I need to
  explain why it's not a concern for these statistics in general.} %

\section{Conclusion}\label{sec:4}
This paper presents an \oos\ test statistic similar to \poscw\ that is
asymptotically normal when comparing nested or non-nested models.
Normality is achieved by estimating the alternative model using a
fixed-length rolling window---as do Clark and West---but estimating
the benchmark model with a recursive window.  Simulations indicate
that the new statistic behaves similarly to Clark and West's original
test when the \dgp\ is stable but can have much higher power when the 
\dgp\ has structural breaks.

\bibliography{texextra/AllRefs}
\end{document}

% LocalWords:  ClW JEL ISI Google GiW Mcc ClM CoS CCS StW IMA GiR WeM fh X'X hh
% LocalWords:  PaT AllRefs isi ima uc sv PeT GoW lm il GoK RoW Econometrica PoR
% LocalWords:  Finan StepM studentizing studentization Whi HuW RSW recentering
% LocalWords:  DiM LiS Kun McCracken lt filtrations GoJR JoD McCracken's Econom
% LocalWords:  Corradi unstudentized studentized GoJ gcalhoun HLN li PoW
% LocalWords:  Econometricians reestimate PPW resample miscentered AnG eq Helle
% LocalWords:  Bunzel Yu Hsu Pincheira HHK th AtO ik DoH Wolak's Wol stepdown
% LocalWords:  Hsu's iq mk Ames Amit Goyal rfs Ivo Welch Wes covariance MeR McW
% LocalWords:  familywise prespecified CoD Gia pointwise misspecified InK MeP
% LocalWords:  VeR xtable Dah dbframe oos parametrizations iid dgp return's CaT
% LocalWords:  outperformance Hmisc Har nondifferentiable bT jt Meng
% LocalWords:  stationarity mixingale mixingales texextra Timmermann